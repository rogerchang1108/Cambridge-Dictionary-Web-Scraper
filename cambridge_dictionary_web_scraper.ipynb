{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f6d988",
   "metadata": {},
   "source": [
    "# Cambridge Dictionary Web Scraper\n",
    "\n",
    " We will scrape the pages on the cambridge dictionary website, and set up a custom dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57936801",
   "metadata": {},
   "source": [
    "### Get the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl https://dictionary.cambridge.org/browse/english-chinese-traditional | egrep -o 'https://dictionary.cambridge.org/browse/english-chinese-traditional/[^/]+/' > toc1.url.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat toc1.url.txt | xargs curl > toc1.page.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ace0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! egrep -o 'https://dictionary.cambridge.org/browse/english-chinese-traditional/[^/]+?/[^\"]+' toc1.page.txt > toc2.url.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e259866",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat toc2.url.txt | xargs curl > toc2.page.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03e3ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! egrep -o \"/dictionary/english-chinese-traditional/[^\\\"\\'']+\" toc2.page.txt | awk '{print \"http://dictionary.cambridge.org/\"$0}' > toc3.url.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e73b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head toc3.url.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3fdaf",
   "metadata": {},
   "source": [
    "### Scrape the webpage\n",
    "\n",
    "Now, we have a bunch of URLs linking to the webpages that we want to scrape. We are going to use the scraping package **BeautifulSoup4**. You can check up their documentation for usage.\n",
    "\n",
    "[BeautifulSoup4 Official Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf0641-0617-4ee1-b016-8c1bae67cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e264bf7",
   "metadata": {},
   "source": [
    "#### Test if web requests work\n",
    "\n",
    "Test if the http request would work or not. If the result doesn't look right please let us know (or try to debug it yourself!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be124c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://dictionary.cambridge.org/dictionary/english-chinese-traditional/accident' # example\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36\"  # this is to bypass the limitation from the cambridge dictionary server\n",
    "headers = {'User-Agent': user_agent}\n",
    "web_request = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(web_request.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba802839",
   "metadata": {},
   "source": [
    "#### Get the head word of the page\n",
    "\n",
    "You may find that some of the results are having multiple lines, but that's okay. Just adjust it in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "921cbafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident\n"
     ]
    }
   ],
   "source": [
    "for sents in soup.findAll('span', {'class': 'hw dhw'}):\n",
    "    print(sents.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685a574",
   "metadata": {},
   "source": [
    "#### Get the pos of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6347e89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun\n"
     ]
    }
   ],
   "source": [
    "for sents in soup.findAll('span', {'class': 'pos dpos'}):\n",
    "    print(sents.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95cdec",
   "metadata": {},
   "source": [
    "#### Get the definition of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfdf7e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something bad that happens that is not expected or intended and that often damages something or injures someone\n",
      "without intending to, or without being intended\n"
     ]
    }
   ],
   "source": [
    "for sents in soup.findAll('div', {'class': 'ddef_h'}):\n",
    "    print(sents.find('div', {'class': 'def ddef_d db'}).get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7fb9f",
   "metadata": {},
   "source": [
    "#### Translation (of the definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14df19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "意外；不測；事故\n",
      "偶然地，意外地\n"
     ]
    }
   ],
   "source": [
    "for sents in soup.findAll('span', {'class': 'trans dtrans dtrans-se break-cj'}):\n",
    "    print(sents.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90890e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Josh had an accident and spilled water all over his work.\n",
      "She was injured in a car/road accident (= when one car hit another).\n",
      "I deleted the file by accident.\n",
      "I found her letter by accident as I was looking through my files.\n"
     ]
    }
   ],
   "source": [
    "for sents in soup.findAll('span', {'class': 'eg deg'}):\n",
    "    print(sents.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14348890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喬希不小心把作業上灑得都是水。\n",
      "她在一宗車禍／交通意外中受傷了。\n",
      "我不小心刪掉了那個檔案。\n",
      "我在查看我的文件時，意外地發現了她的信。\n"
     ]
    }
   ],
   "source": [
    "for sents in soup.findAll('span', {'class': 'trans dtrans dtrans-se hdb break-cj'}):\n",
    "    print(sents.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d57fe",
   "metadata": {},
   "source": [
    "#### Real implementation of the scraping!\n",
    "\n",
    "Create (python) dictionary by scraping the website using bs4. <br><br>\n",
    "\n",
    "Note: Because scraping every URLs in the .txt file may take a LOT of time, we are only working with the first 1000 URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0765ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "\n",
    "url_list = []\n",
    "#for url in open('test.txt', 'r').readlines():\n",
    "for url in open('toc3.url.txt', 'r').readlines():\n",
    "    url_list.append(url.rstrip())\n",
    "\n",
    "word_dict = {}\n",
    "\n",
    "for url in url_list[:1000]:\n",
    "    web_request = None\n",
    "\n",
    "    headword = None\n",
    "    current_dict = {}\n",
    "\n",
    "    retry_count = 0\n",
    "\n",
    "    # send request\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36\"  # this is to bypass the limitation from the cambridge dictionary server\n",
    "    headers = {'User-Agent': user_agent}\n",
    "\n",
    "    while retry_count < 3:\n",
    "        web_request = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(web_request.text, \"html.parser\")\n",
    "\n",
    "        # get elements from the page\n",
    "        if soup.find('div', {'class': 'di-body'}) != None:\n",
    "            di_body = soup.find('div', {'class': 'di-body'})\n",
    "\n",
    "            # get Headword\n",
    "            if di_body.find('h2', {'class': re.compile(r'headword tw-bw dhw dpos-h_hw.*')}) != None:\n",
    "                headword = di_body.find('h2', {'class': re.compile(r'headword tw-bw dhw dpos-h_hw.*')}).get_text()\n",
    "            elif di_body.find('span', {'class': 'hw dhw'}) != None:\n",
    "                headword = di_body.find('span', {'class': 'hw dhw'}).get_text()\n",
    "            else:\n",
    "                headword = url\n",
    "            current_dict['Headword'] = headword\n",
    "            \n",
    "            entry_array = []\n",
    "\n",
    "            # check structure\n",
    "            if di_body.find('div', {'class': 'pr entry-body__el'}) != None:\n",
    "                entry_body = di_body.find_all('div', {'class': 'pr entry-body__el'})\n",
    "            else:\n",
    "                entry_body = soup.find_all('div', {'class': 'di-body'})\n",
    "\n",
    "            for entry in entry_body:\n",
    "                entry_array_dict = {}\n",
    "\n",
    "                # check POS\n",
    "                if entry.find('span', {'class': 'pos dpos'}) != None:\n",
    "                    POS_array = []\n",
    "\n",
    "                    # get POS\n",
    "                    for POS_span in entry.find_all('span', {'class': 'pos dpos'}):\n",
    "                        POS_array.append(POS_span.text)\n",
    "                    entry_array_dict['POS'] = POS_array \n",
    "                else:\n",
    "                    entry_array_dict['POS'] = 'N/A'\n",
    "\n",
    "                sense_body_array = []\n",
    "\n",
    "                for sense_body in entry.find_all('div', {'class': 'sense-body dsense_b'}):\n",
    "\n",
    "                    # check DEFINITIONS\n",
    "                    if sense_body.find('div', {'class': 'def-block ddef_block'}, recursive=False) != None:\n",
    "\n",
    "                        for def_block in sense_body.find_all('div', {'class': 'def-block ddef_block'}, recursive=False):\n",
    "                            def_block_array_dict = {}\n",
    "\n",
    "                            # get DEFINITION-ENG\n",
    "                            if def_block.find('div', {'class': 'def ddef_d db'}) != None:\n",
    "                                def_block_array_dict['DEFINITION-ENG'] = def_block.find('div', {'class': 'def ddef_d db'}).get_text()\n",
    "                            else:\n",
    "                                def_block_array_dict['DEFINITION-ENG'] = 'N/A'\n",
    "\n",
    "                            # get DEFINITION-CHI\n",
    "                            if def_block.find('span', {'class': 'trans dtrans dtrans-se break-cj'}) != None:\n",
    "                                def_block_array_dict['DEFINITION-CHI'] = def_block.find('span', {'class': 'trans dtrans dtrans-se break-cj'}).get_text()\n",
    "                            else:\n",
    "                                def_block_array_dict['DEFINITION-CHI'] = 'N/A'\n",
    "                            \n",
    "                            if def_block.find('div', {'class': 'examp dexamp'}) != None:\n",
    "                                examp_array = []\n",
    "\n",
    "                                # get EXAMPLE-SENTS\n",
    "                                for examples in def_block.find_all('div', {'class': 'examp dexamp'}):\n",
    "                                    examp_array_dict = {}\n",
    "\n",
    "                                    # get SENT\n",
    "                                    examp_array_dict['SENT'] = examples.find('span', {'class': 'eg deg'}).get_text()\n",
    "\n",
    "                                    # get SENT-CHT\n",
    "                                    if examples.find('span', {'class': 'trans dtrans dtrans-se hdb break-cj'}) != None:\n",
    "                                        examp_array_dict['SENT-CHT'] = examples.find('span', {'class': 'trans dtrans dtrans-se hdb break-cj'}).get_text()\n",
    "                                    else:\n",
    "                                        examp_array_dict['SENT-CHT'] = 'N/A'\n",
    "\n",
    "                                    examp_array.append(examp_array_dict)\n",
    "\n",
    "                                def_block_array_dict['EXAMPLE-SENTS'] = examp_array\n",
    "                            \n",
    "                            else: \n",
    "                                def_block_array_dict['EXAMPLE-SENTS'] = 'N/A'\n",
    "\n",
    "                            sense_body_array.append(def_block_array_dict)\n",
    "\n",
    "                    # check PHRASE\n",
    "                    if sense_body.find('div', {'class': re.compile(r'pr phrase-block dphrase-block.*')}) != None:\n",
    "\n",
    "                        for phrase_block in sense_body.find_all('div', {'class': re.compile(r'pr phrase-block dphrase-block.*')}):\n",
    "                            phrase_block_array_dict = {}\n",
    "\n",
    "                            # get PHRASE\n",
    "                            phrase_block_array_dict['PHRASE'] = phrase_block.find('span', {'class': 'phrase-title dphrase-title'}).get_text()\n",
    "                            \n",
    "                            phrase_body = phrase_block.find('div', {'class': 'phrase-body dphrase_b'})\n",
    "\n",
    "                            def_block_array = []\n",
    "\n",
    "                            # get PHRASE-DEFINITIONS\n",
    "                            for def_block in phrase_body.find_all('div', {'class': 'def-block ddef_block'}, recursive=False):\n",
    "                                def_block_array_dict = {}\n",
    "\n",
    "                                # get PHRASE-DEFINITION-ENG\n",
    "                                def_block_array_dict['PHRASE-DEFINITION-ENG'] = def_block.find('div', {'class': 'def ddef_d db'}).get_text()\n",
    "\n",
    "                                # get PHRASE-DEFINITION-CHT\n",
    "                                if def_block.find('span', {'class': 'trans dtrans dtrans-se break-cj'}) != None:\n",
    "                                    def_block_array_dict['PHRASE-DEFINITION-CHI'] = def_block.find('span', {'class': 'trans dtrans dtrans-se break-cj'}).get_text()\n",
    "\n",
    "                                def_block_array.append(def_block_array_dict)\n",
    "\n",
    "                            phrase_block_array_dict['PHARSE-BODY'] = def_block_array\n",
    "\n",
    "                            sense_body_array.append(phrase_block_array_dict)\n",
    "                        \n",
    "                entry_array_dict['POS-BODY'] = sense_body_array\n",
    "\n",
    "                entry_array.append(entry_array_dict)\n",
    "\n",
    "            # put the entry to current_dict\n",
    "            current_dict['ENTRY'] = entry_array\n",
    "\n",
    "            # put the word to word_dict\n",
    "            word_dict[headword] = current_dict\n",
    "\n",
    "            break\n",
    "        \n",
    "        retry_count += 1\n",
    "\n",
    "    if retry_count == 3:\n",
    "        current_dict['Headword'] = url\n",
    "        current_dict['ENTRY'] = 'url request fail'\n",
    "        word_dict[headword] = current_dict\n",
    "\n",
    "# save dict\n",
    "json_str = json.dumps(word_dict, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(\"result.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(json_str)\n",
    "\n",
    "# print dict\n",
    "word_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823768e-a9e4-4dc3-a135-9745a1a6f29f",
   "metadata": {},
   "source": [
    "### Output example\n",
    "`word_dict['accident']`\n",
    "```json\n",
    "{\n",
    "    'HEADWORD': accident,\n",
    "    'POS': ...,\n",
    "    'DEFINITION-ENG': ...,\n",
    "    'DEFINITION-CHI': ...,\n",
    "    'EXAMPLE-SENTS': [\n",
    "                    {'SENT': ...,\n",
    "                    'SENT-CHI': ...},\n",
    "                    ...],\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1896deee",
   "metadata": {},
   "source": [
    "#### Test if the result is available\n",
    "\n",
    "Let's try the word 'accident.' See what we got here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "166d75bd-dacf-4efb-b90f-cb5bc9a37586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Headword': 'accident',\n",
       " 'ENTRY': [{'POS': ['noun'],\n",
       "   'POS-BODY': [{'DEFINITION-ENG': 'something bad that happens that is not expected or intended and that often damages something or injures someone',\n",
       "     'DEFINITION-CHI': '意外；不測；事故',\n",
       "     'EXAMPLE-SENTS': [{'SENT': 'Josh had an accident and spilled water all over his work.',\n",
       "       'SENT-CHT': '喬希不小心把作業上灑得都是水。'},\n",
       "      {'SENT': 'She was injured in a car/road accident (= when one car hit another).',\n",
       "       'SENT-CHT': '她在一宗車禍／交通意外中受傷了。'}]},\n",
       "    {'PHRASE': 'by accident',\n",
       "     'PHARSE-BODY': [{'PHRASE-DEFINITION-ENG': 'without intending to, or without being intended',\n",
       "       'PHRASE-DEFINITION-CHI': '偶然地，意外地'}]}]}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict['accident']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5498c41677c90337ab05595a4a5458c6f8e1016176aa560ce289c59d829e8531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
